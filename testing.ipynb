{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import M\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from yolo import Yolo\n",
    "from loss import Loss\n",
    "from utils import  AverageMeter,class_accuracy\n",
    "from dataset import get_data\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Yolo(3,6//2,2)\n",
    "model.load_state_dict(torch.load('model_1111.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 13, 13, 7]) torch.Size([1, 3, 26, 26, 7])\n",
      "torch.Size([1, 21, 13, 13]) torch.Size([1, 21, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1,3,416,416)\n",
    "with torch.no_grad():\n",
    "    out_feat = model(x)\n",
    "print(out_feat[0].shape, out_feat[1].shape)\n",
    "out13 = torch.reshape(out_feat[0], (1,21,13,13))\n",
    "out26 = torch.reshape(out_feat[1], (1,21,26,26))\n",
    "print(out13.shape, out26.shape)\n",
    "my_out = [out13, out26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeBox(nn.Module):\n",
    "    def __init__(self, scaled_anchors, num_classes, img_size):\n",
    "        super(DecodeBox, self).__init__()\n",
    "        self.scaled_anchors = scaled_anchors\n",
    "        self.num_anchors = len(scaled_anchors)\n",
    "        self.num_classes = num_classes\n",
    "        self.bbox_attrs = 5 + num_classes\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        input_height = input.size(2)\n",
    "        input_width = input.size(3)\n",
    "        stride_h = self.img_size[1] / input_height\n",
    "        stride_w = self.img_size[0] / input_width\n",
    "        scaled_anchors = self.scaled_anchors\n",
    "\n",
    "        prediction = input.view(batch_size, self.num_anchors,\n",
    "                                self.bbox_attrs, input_height, input_width).permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = torch.sigmoid(prediction[..., 0])\n",
    "        y = torch.sigmoid(prediction[..., 1])\n",
    "        w = prediction[..., 2]\n",
    "        h = prediction[..., 3]\n",
    "        conf = torch.sigmoid(prediction[..., 4])\n",
    "        pred_cls = torch.sigmoid(prediction[..., 5:])\n",
    "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
    "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
    "        grid_x = torch.linspace(0, input_width - 1, input_width).repeat(input_height, 1).repeat(\n",
    "            batch_size * self.num_anchors, 1, 1).view(x.shape).type(FloatTensor)\n",
    "        grid_y = torch.linspace(0, input_height - 1, input_height).repeat(input_width, 1).t().repeat(\n",
    "            batch_size * self.num_anchors, 1, 1).view(y.shape).type(FloatTensor)\n",
    "        anchor_w = FloatTensor(scaled_anchors).index_select(1, LongTensor([0]))\n",
    "        anchor_h = FloatTensor(scaled_anchors).index_select(1, LongTensor([1]))\n",
    "        anchor_w = anchor_w.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(w.shape)\n",
    "        anchor_h = anchor_h.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(h.shape)\n",
    "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
    "        pred_boxes[..., 0] = x.data + grid_x\n",
    "        pred_boxes[..., 1] = y.data + grid_y\n",
    "        pred_boxes[..., 2] = torch.exp(w.data) * anchor_w\n",
    "        pred_boxes[..., 3] = torch.exp(h.data) * anchor_h\n",
    "        scale = torch.Tensor([stride_w, stride_h] * 2).type(FloatTensor)\n",
    "        output = torch.cat((pred_boxes.view(batch_size, -1, 4) * scale,\n",
    "                            conf.view(batch_size, -1, 1), pred_cls.view(batch_size, -1, self.num_classes)), -1)\n",
    "        return output.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [13,26]\n",
    "ANCHORS =  [[(0.275 ,   0.320312), (0.068   , 0.113281), (0.017  ,  0.03   )], \n",
    "           [(0.03  ,   0.056   ), (0.01  ,   0.018   ), (0.006 ,   0.01    )]]\n",
    "\n",
    "scaled_anchors = (\n",
    "        torch.tensor(ANCHORS)\n",
    "        * torch.tensor(S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n",
    "    ).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_decoder=[]\n",
    "anchor_arr=[[3,4,5],[0,1,2]]\n",
    "for i in range(2):\n",
    "    decoder=DecodeBox(np.reshape(scaled_anchors,[-1,2])[anchor_arr[i]],2,(416,416))\n",
    "    feat_decoder.append(decoder)\n",
    "    \n",
    "out_list=[]\n",
    "for i in range(2):\n",
    "        decoder_out=feat_decoder[i](my_out[i])\n",
    "        out_list.append(decoder_out)\n",
    "                \n",
    "output=torch.cat(out_list,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2535, 7])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_temp=output.new(output.shape)\n",
    "box_temp[:,:,0]=output[:,:,0]-output[:,:,2]/2\n",
    "box_temp[:,:,1]=output[:,:,1]-output[:,:,3]/2\n",
    "box_temp[:,:,2]=output[:,:,0]+output[:,:,2]/2\n",
    "box_temp[:,:,3]=output[:,:,1]+output[:,:,3]/2\n",
    "output[:,:,:4]=box_temp[:,:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, p in enumerate(output):\n",
    "    cls_conf,cls_pred=torch.max(p[:,5:7],dim=1,keepdim=True)\n",
    "    score = p[:,4]*cls_conf[:,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4612],\n",
       "         [0.6822],\n",
       "         [0.6656],\n",
       "         ...,\n",
       "         [0.7613],\n",
       "         [0.4670],\n",
       "         [0.8994]]),\n",
       " tensor([[1],\n",
       "         [0],\n",
       "         [1],\n",
       "         ...,\n",
       "         [1],\n",
       "         [0],\n",
       "         [1]]),\n",
       " tensor([0.2506, 0.4196, 0.2725,  ..., 0.4478, 0.3850, 0.0675]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_conf, cls_pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(score > 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2535"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cls_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1037e+01, 2.0090e+01, 2.3804e+01, 5.8630e+01, 6.1508e-01, 6.8219e-01,\n",
       "         5.4797e-05]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:,1,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
